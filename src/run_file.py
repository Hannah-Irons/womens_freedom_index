'''
RUN file for Udacity Data science nanodegree: Project One - Write a Data Science Blog Post
Author: Hannah Costa

The data choosen for this assigmnet was the Human Freedom Index data avaialble on Kaggle.
LINK: https://www.kaggle.com/gsutters/the-human-freedom-index

The Human index data combines measures of economic and personal freedom to assign a total 
Human freedom score to a country and rank it based on this score. The survey has been 
conducted since 2008 for the earliest definition, and the most recent data availiable is 
from 2019, which is used in this assignment. 

The data available isn't the raw data from the Freedom project, and is made up of the econmic 
and personal freedom factors that are all on a scoredbscale between 0-10. The Human Freedom 
report offers some insight in the meanings behind these factors but that their definitions, 
or what the score directly translates to numerically.

For example the pf_ss_women_fgm factor relates to Female Genital Mutilations in a country but 
the score doesn't tell me if it's based on number of cases reported per population percentage.
'pf' in a factor means that it's used to create a Personal freedom factor and 'ss' means it's 
in the 'Security and Safety' category. 

The freedom indicators covered by the report are:

Rule of Law
Security and Safety
Movement
Religion
Association, Assembly, and Civil Society
Expression and Information
Identity and Relationships
Size of Government
Legal System and Property Rights
Access to Sound Money
Freedom to Trade Internationally
Regulation of Credit, Labor, and Business

This Run file will call functions and scripts with the purpose of reading in the data and 
processing it so it can be used to explore correlations and insights in the data while
focusing on the implications of Women's freedom. The author is using python 3.8.5 with 
Visual Studio as an interface.

'''
# Call the libraries

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import seaborn as sns

# All data and scripts are kept in the same location. however can use the os library to 
# retrieve the location path and change directory if necessary. 
# print(os.getcwd())
# os.chdir('./"path_to_data"')

# Import function file for access to all functiosn written for this assignment
import function_file as functions

# Read dataset into a dataframe
df = pd.read_csv('./data/datasets_93172_883723_hfi_cc_2019.csv')
# Check the first handful of rows to ensure the data was retrieved. note: 120 columns expected
print(df.head())

# Because of the processed nature of the data set I want to drop some of the factors that
# are generated by the more base factors.
df = df.drop(["ISO_code", "ef_score","pf_score", "pf_rank", "ef_rank", "hf_rank", "hf_quartile"], axis = 1)

# print(df.dtypes)
# The whole dataset comes in as "objects" despite the mojority of the data being a numerical score. 
# The next step would be convert the columns that can be converted to floats in order to be able
# to perform numerical analysis on the dataset. 

functions.convert_float(df)

# create a list of columns that have more than 25% of their values missing.

col_list = functions.most_missing_col(df, 0.25)

# Check column list to be aquantited with what's being dropped
# print(col_list)

# Drop the columns that have the most missing values
df = df.drop(col_list, axis=1)

Region_list = list(set(df["region"]))

# Check that Region_list has populated correctly because I'm not typing them out by hand.
# print(Region_list)

# Loop over region_list for avage scores for hf_score and pf_ss_women score. Plot togther for 
# each country per Region. Save the figues so they do not overwrite each other. 

for region in Region_list:
  region_pf_women = functions.country_per_region(region, "pf_ss_women", df)
  region_hf_score = functions.country_per_region(region, "hf_score", df)
  functions.plot_save_Region_correlation(region_hf_score, region_pf_women, region)


functions.correlations_top_bottom(df, "Sub-Saharan Africa", "pf_ss_women", 10)
# functions.correlations_top_bottom(df, "Middle east & North Africa", "pf_ss_women", 10)
# functions.correlations_top_bottom(df, "Western Europe", "pf_ss_women", 10)


# Closer look at the correlation for Sub saharan Africa
var_list = ["ef_legal_judicial", "ef_legal_military", "ef_regulation_business_bribes", "ef_government_transfers", "ef_trade_tariffs_sd", "ef_government_consumption"]

plt.figure(figsize = (10,8))
plt.xlabel("variable score")
plt.ylabel("mean pf_ss_women score")
plt.title("The average personal women's freedom score aggregated for the top correlated factors. \n Sub-Saharan Africa")
plt.grid(True)

d = {}
for var in var_list:
  d[var] = functions.variable_per_region("Sub-Saharan Africa", var, "pf_ss_women", df)
  plt.plot(d[var], 'o')

plt.legend((var_list), loc ='lower right')
plt.savefig('./results/scatter_correlations_SSA.png')

plt.close()

#  Can you model womens's freedomn using only economic factors per region.

df_modelling = df.dropna(subset = ["pf_ss_women"], axis = 0)

X = df_modelling.filter(regex = '^ef', axis = 1)
y = df_modelling["pf_ss_women"]

fill_mean = lambda col: col.fillna(col.mean())

# I've kept the following function inside the run_file instead of the function_file to toggle the different print functions on and off when debugging.
for col in X:
  if X[col].isnull().sum() == 0:
    # print(col + " no NaN's")
    continue
  else:
    try:
      X = X.apply(fill_mean, axis = 0)
      print(col + " worked as expected")
    except:
      print(col + " did not replace NaN with mean")


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 15)
lm_model = LinearRegression(normalize = True)
lm_model.fit(X_train, y_train)

Score = str(lm_model.score(X_test, y_test, sample_weight = None))

print("The Model preformed with a Score of " + Score)